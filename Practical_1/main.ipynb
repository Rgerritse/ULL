{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Word Representations\n",
    "Matthew van Rijn - 10779353 <br />\n",
    "Ruben gerritse - 10760326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from operator import itemgetter\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.palettes import d3\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.layouts import column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the word embeddings. This may take a while.\n",
    "# NOTE: The number of words and embedding dimension must be added to the\n",
    "# first line before loading.\n",
    "embeddings = ['deps', 'bow2', 'bow5']\n",
    "models = {x: KeyedVectors.load_word2vec_format('{}.words'.format(x)) for x in embeddings}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Similarity Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extra data from the simlex dataset to allow it to be loaded by GenSim\n",
    "with open('SimLex-999/SimLex-999.txt', 'r') as f:\n",
    "    data = f.read().strip().split('\\n')\n",
    "    data_sim = [itemgetter(*[0, 1, 3])(line.split()) for line in data][1:]\n",
    "\n",
    "with open('SimLex-999/SimLex-converted.txt', 'w+') as f:\n",
    "    for line in data_sim:\n",
    "        f.write(' '.join(line) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating with deps\n",
      "Pearson:  0.5974/1.02E-289\n",
      "Spearman: 0.6178/2.37E-315 (MEN/MEN_dataset_natural_form_full)\n",
      "\n",
      "Pearson:  0.4619/6.84E-54\n",
      "Spearman: 0.4456/7.41E-50 (SimLex-999/SimLex-converted.txt)\n",
      "\n",
      "Evaluating with bow2\n",
      "Pearson:  0.6777/0.00E+00\n",
      "Spearman: 0.6999/0.00E+00 (MEN/MEN_dataset_natural_form_full)\n",
      "\n",
      "Pearson:  0.4285/7.99E-46\n",
      "Spearman: 0.4141/1.23E-42 (SimLex-999/SimLex-converted.txt)\n",
      "\n",
      "Evaluating with bow5\n",
      "Pearson:  0.7082/0.00E+00\n",
      "Spearman: 0.7232/0.00E+00 (MEN/MEN_dataset_natural_form_full)\n",
      "\n",
      "Pearson:  0.3756/8.61E-35\n",
      "Spearman: 0.3674/2.98E-33 (SimLex-999/SimLex-converted.txt)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the Pearson and Spearman correlation coefficients\n",
    "datasets = ['MEN/MEN_dataset_natural_form_full', 'SimLex-999/SimLex-converted.txt']\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print('Evaluating with {}'.format(model_name))\n",
    "    for dataset in datasets:\n",
    "        ((pc, pp),(sc, sp),_) = model.evaluate_word_pairs(dataset, delimiter=' ')\n",
    "        print('Pearson:  {:.4f}/{:.2E}\\nSpearman: {:.4f}/{:.2E} ({})\\n'.format(pc, pp, sc, sp, dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Analogy Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('questions-words.txt') as f:\n",
    "    data = [category.split('\\n')[:-1] for category in f.read().strip().split(': ')[1:]]\n",
    "    data = {category[0]: [tuple(word.lower().split()) for word in category[1:]] for category in data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model deps:\n",
      "00506/00506 Accuracy: 0.3518 MRR: 0.4939 (capital-common-countries)\n",
      "04524/04524 Accuracy: 0.1121 MRR: 0.2035 (capital-world)\n",
      "00866/00866 Accuracy: 0.0638 MRR: 0.0958 (currency)\n",
      "02467/02467 Accuracy: 0.1228 MRR: 0.2208 (city-in-state)\n",
      "00506/00506 Accuracy: 0.8162 MRR: 0.8541 (family)\n",
      "00992/00992 Accuracy: 0.0343 MRR: 0.0668 (gram1-adjective-to-adverb)\n",
      "00812/00812 Accuracy: 0.4002 MRR: 0.4763 (gram2-opposite)\n",
      "01332/01332 Accuracy: 0.8011 MRR: 0.8535 (gram3-comparative)\n",
      "01122/01122 Accuracy: 0.5606 MRR: 0.6372 (gram4-superlative)\n",
      "01056/01056 Accuracy: 0.6468 MRR: 0.7402 (gram5-present-participle)\n",
      "01599/01599 Accuracy: 0.1213 MRR: 0.2199 (gram6-nationality-adjective)\n",
      "01560/01560 Accuracy: 0.6590 MRR: 0.7320 (gram7-past-tense)\n",
      "01332/01332 Accuracy: 0.6757 MRR: 0.7478 (gram8-plural)\n",
      "00869/00869 Accuracy: 0.9091 MRR: 0.9447 (gram9-plural-verbs)\n",
      "19543/19543 Accuracy: 0.3672 MRR: 0.4456 (overall)\n",
      "\n",
      "Evaluating model bow2:\n",
      "00506/00506 Accuracy: 0.8360 MRR: 0.8817 (capital-common-countries)\n",
      "04524/04524 Accuracy: 0.6302 MRR: 0.7195 (capital-world)\n",
      "00866/00866 Accuracy: 0.1130 MRR: 0.1480 (currency)\n",
      "02467/02467 Accuracy: 0.3924 MRR: 0.4976 (city-in-state)\n",
      "00506/00506 Accuracy: 0.7945 MRR: 0.8538 (family)\n",
      "00992/00992 Accuracy: 0.1593 MRR: 0.2357 (gram1-adjective-to-adverb)\n",
      "00812/00812 Accuracy: 0.3559 MRR: 0.4234 (gram2-opposite)\n",
      "01332/01332 Accuracy: 0.8956 MRR: 0.9389 (gram3-comparative)\n",
      "01122/01122 Accuracy: 0.6307 MRR: 0.7300 (gram4-superlative)\n",
      "01056/01056 Accuracy: 0.6269 MRR: 0.7470 (gram5-present-participle)\n",
      "01599/01599 Accuracy: 0.7417 MRR: 0.8073 (gram6-nationality-adjective)\n",
      "01560/01560 Accuracy: 0.5571 MRR: 0.6626 (gram7-past-tense)\n",
      "01332/01332 Accuracy: 0.7327 MRR: 0.7926 (gram8-plural)\n",
      "00869/00869 Accuracy: 0.8067 MRR: 0.8646 (gram9-plural-verbs)\n",
      "19543/19543 Accuracy: 0.5929 MRR: 0.6738 (overall)\n",
      "\n",
      "Evaluating model bow5:\n",
      "00506/00506 Accuracy: 0.9407 MRR: 0.9639 (capital-common-countries)\n",
      "04524/04524 Accuracy: 0.7029 MRR: 0.7989 (capital-world)\n",
      "00866/00866 Accuracy: 0.1223 MRR: 0.1686 (currency)\n",
      "02467/02467 Accuracy: 0.5128 MRR: 0.6213 (city-in-state)\n",
      "00506/00506 Accuracy: 0.8182 MRR: 0.8698 (family)\n",
      "00992/00992 Accuracy: 0.1694 MRR: 0.2721 (gram1-adjective-to-adverb)\n",
      "00812/00812 Accuracy: 0.3633 MRR: 0.4321 (gram2-opposite)\n",
      "01332/01332 Accuracy: 0.8303 MRR: 0.8917 (gram3-comparative)\n",
      "01122/01122 Accuracy: 0.5710 MRR: 0.6988 (gram4-superlative)\n",
      "01056/01056 Accuracy: 0.6705 MRR: 0.7819 (gram5-present-participle)\n",
      "01599/01599 Accuracy: 0.8236 MRR: 0.8648 (gram6-nationality-adjective)\n",
      "01560/01560 Accuracy: 0.5468 MRR: 0.6662 (gram7-past-tense)\n",
      "01332/01332 Accuracy: 0.6682 MRR: 0.7523 (gram8-plural)\n",
      "00869/00869 Accuracy: 0.7353 MRR: 0.8216 (gram9-plural-verbs)\n",
      "19543/19543 Accuracy: 0.6228 MRR: 0.7111 (overall)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    print('Evaluating model {}:'.format(model_name))\n",
    "    total_acc = []\n",
    "    total_mrr = []\n",
    "    total_len = 0\n",
    "    for category in data:\n",
    "        acc = []\n",
    "        mrr = []\n",
    "        total = len(data[category])\n",
    "        for i, (w1, w2, w3, w4) in enumerate(data[category]):\n",
    "            if w4 in model:\n",
    "                try:\n",
    "                    ranking = model.most_similar(positive=[w2, w3], negative=[w1], topn=1000)\n",
    "                    ranking = [word for word, _ in ranking]\n",
    "\n",
    "                    # Collect stats\n",
    "                    acc.append(ranking[0] == w4)\n",
    "                    try:\n",
    "                        mrr.append(1/(ranking.index(w4)+1))\n",
    "                    except ValueError:\n",
    "                        mrr.append(0)\n",
    "                except KeyError:\n",
    "                    continue\n",
    "\n",
    "            # Print progress bar\n",
    "            if i % 10 == 0 or i+1 == total:\n",
    "                print('\\r{:05d}/{:05d}'.format(i+1, total), end='')\n",
    "\n",
    "        total_acc += acc\n",
    "        total_mrr += mrr\n",
    "        total_len += total\n",
    "\n",
    "        print(' Accuracy: {:.4f} MRR: {:.4f} ({})'.format(sum(acc)/len(acc), sum(mrr)/len(mrr), category))\n",
    "    print('{0:05d}/{0:05d} Accuracy: {1:.4f} MRR: {2:.4f} (overall)\\n'.format(total_len, sum(total_acc)/len(total_acc), sum(total_mrr)/len(total_mrr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Word Vectors\n",
    "The results are plotted in the output html file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file(\"cluster-output.html\")\n",
    "\n",
    "def get_model_plot(name, model, words, N=20, perplexity=30.0):\n",
    "    word_list = []\n",
    "    vectors = []\n",
    "    for word in words:\n",
    "        if word in model.vocab:\n",
    "            word_list.append(word)\n",
    "            vectors.append(model[word])\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=N)\n",
    "    kmeans.fit(vectors)\n",
    "    clusters = kmeans.labels_\n",
    "\n",
    "    tsne = TSNE(n_components=2, perplexity=perplexity)\n",
    "    tsne_vectors = tsne.fit_transform(vectors)\n",
    "    \n",
    "    p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
    "               toolbar_location=\"above\",\n",
    "               title=\"T-SNE for 2000 nouns with {}.words\".format(name))\n",
    "\n",
    "    colormap = d3['Category20'][N]\n",
    "    colors = [colormap[i%20] for i in clusters]\n",
    "\n",
    "    source = ColumnDataSource(data=dict(x1=tsne_vectors[:,0],\n",
    "                                        x2=tsne_vectors[:,1],\n",
    "                                        names=word_list,\n",
    "                                        colors=colors))\n",
    "\n",
    "    p.scatter(x=\"x1\", y=\"x2\", size=8, source=source, color='colors')\n",
    "\n",
    "    labels = LabelSet(x=\"x1\", y=\"x2\", text=\"names\", y_offset=6,\n",
    "                      text_font_size=\"8pt\", text_color=\"#555555\",\n",
    "                      source=source, text_align='center')\n",
    "    p.add_layout(labels)\n",
    "\n",
    "    return p\n",
    "\n",
    "N = 20\n",
    "\n",
    "with open(\"2000_nouns_sorted.txt\") as file: \n",
    "    words = [x.strip() for x in file.readlines()] \n",
    "\n",
    "p_list = []\n",
    "for name, model in models.items():\n",
    "    p_list.append(get_model_plot(name, model, words))\n",
    "show(column(p_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
