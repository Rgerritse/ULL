# UNSUPERVISED LANGUAGE LEARNING
Matthew van Rijn<br>
Ruben Gerritse

### Practical 1: Evaluating Word Representations
To run: navigate to Project 1 and open main.ipynb.

### Practical 2: Learning Word Representations
The three main models can be trained from different files:
SG.py for Skip-gram
BSG.py for Bayesian Skip-gram
EA.py for Embed-Align

The scripts are designed to be run interactively, but do not have to be.

The remaining files contain the following:
evaluate.py: code for performing the lexical substitution task
utils.py: code primarily for reading the datasets
stopwords_language: stopwords to map to unknown

The expected data locations are:
data/hansards/ for the hansards dataset
data/lst for the lst dataset and evaluation script


